{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciBERT Fine-Tuning on Drug/ADE Corpus\n",
    "#### Hugging Face Course Community Event\n",
    "#### By Justin S. Lee \n",
    "#### November 15-19, 2021\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we use the ðŸ¤— `transformers` library to fine-tune the `allenai/scibert_scivocab_uncased` model on the dataset `ade_corpus_v2`. The goal is for the fine-tuned model to perform Named Entity Recognition by identifying Adverse Drug Reactions (ADRs) as well as Drug names. \n",
    "\n",
    "This was originally run on an `ml.p3.2xlarge` instance on AWS SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (1.15.1)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (4.11.3)\n",
      "Requirement already satisfied: seqeval in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (4.8.1)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (0.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (0.1.2)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (2021.11.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from packaging->datasets) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.3)\n",
      "Requirement already satisfied: idna-ssl>=1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (1.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (4.0.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->datasets) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.2.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.0 MB 24.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from spacy) (3.0.1)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 451 kB 64.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from spacy) (4.62.3)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from spacy) (1.19.5)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.9 MB 62.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (629 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 629 kB 35.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181 kB 80.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42 kB 2.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp36-cp36m-manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.2 MB 52.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (127 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127 kB 72.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from spacy) (58.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from spacy) (3.10.0.2)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->spacy) (3.0.1)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from pathy>=0.3.5->spacy) (0.8)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58 kB 9.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from thinc<8.1.0,>=8.0.12->spacy) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from contextvars<3,>=2.4->thinc<8.1.0,>=8.0.12->spacy) (0.15)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (4.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "Successfully installed blis-0.7.5 catalogue-2.0.6 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.2.0 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0 wasabi-0.8.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, ClassLabel, Sequence, load_dataset, load_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import transformers\n",
    "from transformers import (AutoModelForTokenClassification, \n",
    "                          AutoTokenizer, \n",
    "                          DataCollatorForTokenClassification,\n",
    "                          pipeline,\n",
    "                          TrainingArguments, \n",
    "                          Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm version > 4.11.0\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset Exploration\n",
    "\n",
    "We use the `Ade_corpus_v2_drug_ade_relation` subset of the `ade_corpus_v2` dataset, which provides labeled spans for drug names and adverse effects.\n",
    "\n",
    "See dataset page here: https://huggingface.co/datasets/ade_corpus_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset ade_corpus_v2 (/home/ec2-user/.cache/huggingface/datasets/ade_corpus_v2/Ade_corpus_v2_drug_ade_relation/1.0.0/940d61334dbfac6b01ac5d00286a2122608b8dc79706ee7e9206a1edb172c559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a928cd71f3764fe4bfcdf7b9f37eb546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"ade_corpus_v2\", \"Ade_corpus_v2_drug_ade_relation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'drug', 'effect', 'indexes'],\n",
       "        num_rows: 6821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Intravenous azithromycin-induced ototoxicity.',\n",
       " 'drug': 'azithromycin',\n",
       " 'effect': 'ototoxicity',\n",
       " 'indexes': {'drug': {'start_char': [12], 'end_char': [24]},\n",
       "  'effect': {'start_char': [33], 'end_char': [44]}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Consolidation\n",
    "----\n",
    "Upon further examination of the dataset, we can see that sentences are often repeated to identify different pairs of drugs and adverse reactions. For example, see this sentence from the dataset:\n",
    "```\n",
    "{'text': 'After therapy for diabetic coma with insulin (containing the preservative cresol) and electrolyte solutions was started, the patient complained of increasing myalgia, developed a high fever and respiratory and metabolic acidosis and lost consciousness.', 'drug': 'insulin', 'effect': 'increasing myalgia', 'indexes': {'drug': {'start_char': [37], 'end_char': [44]}, 'effect': {'start_char': [147], 'end_char': [165]}}}\n",
    "{'text': 'After therapy for diabetic coma with insulin (containing the preservative cresol) and electrolyte solutions was started, the patient complained of increasing myalgia, developed a high fever and respiratory and metabolic acidosis and lost consciousness.', 'drug': 'cresol', 'effect': 'lost consciousness', 'indexes': {'drug': {'start_char': [74], 'end_char': [80]}, 'effect': {'start_char': [233], 'end_char': [251]}}}\n",
    "{'text': 'After therapy for diabetic coma with insulin (containing the preservative cresol) and electrolyte solutions was started, the patient complained of increasing myalgia, developed a high fever and respiratory and metabolic acidosis and lost consciousness.', 'drug': 'cresol', 'effect': 'high fever', 'indexes': {'drug': {'start_char': [74], 'end_char': [80]}, 'effect': {'start_char': [179], 'end_char': [189]}}}\n",
    "{'text': 'After therapy for diabetic coma with insulin (containing the preservative cresol) and electrolyte solutions was started, the patient complained of increasing myalgia, developed a high fever and respiratory and metabolic acidosis and lost consciousness.', 'drug': 'insulin', 'effect': 'high fever', 'indexes': {'drug': {'start_char': [37], 'end_char': [44]}, 'effect': {'start_char': [179], 'end_char': [189]}}}\n",
    "{'text': 'After therapy for diabetic coma with insulin (containing the preservative cresol) and electrolyte solutions was started, the patient complained of increasing myalgia, developed a high fever and respiratory and metabolic acidosis and lost consciousness.', 'drug': 'insulin', 'effect': 'lost consciousness', 'indexes': {'drug': {'start_char': [37], 'end_char': [44]}, 'effect': {'start_char': [233], 'end_char': [251]}}}\n",
    "{'text': 'After therapy for diabetic coma with insulin (containing the preservative cresol) and electrolyte solutions was started, the patient complained of increasing myalgia, developed a high fever and respiratory and metabolic acidosis and lost consciousness.', 'drug': 'insulin', 'effect': 'respiratory and metabolic acidosis', 'indexes': {'drug': {'start_char': [37], 'end_char': [44]}, 'effect': {'start_char': [194], 'end_char': [228]}}}\n",
    "{'text': 'After therapy for diabetic coma with insulin (containing the preservative cresol) and electrolyte solutions was started, the patient complained of increasing myalgia, developed a high fever and respiratory and metabolic acidosis and lost consciousness.', 'drug': 'cresol', 'effect': 'respiratory and metabolic acidosis', 'indexes': {'drug': {'start_char': [74], 'end_char': [80]}, 'effect': {'start_char': [194], 'end_char': [228]}}}\n",
    "```\n",
    "\n",
    "This is not ideal in an NER setting - if we assigned one set of token labels per row in this dataset as-is, we would end up giving different labels to the same tokens in the same sentences. This would confuse the model during fine-tuning, so we need to consolidate all of the ranges provided for each unique sentence, before performing one pass to label all known entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_dataset = {}\n",
    "\n",
    "for row in datasets[\"train\"]:\n",
    "    if row[\"text\"] in consolidated_dataset:\n",
    "        consolidated_dataset[row[\"text\"]][\"drug_indices_start\"].update(row[\"indexes\"][\"drug\"][\"start_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"drug_indices_end\"].update(row[\"indexes\"][\"drug\"][\"end_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect_indices_start\"].update(row[\"indexes\"][\"effect\"][\"start_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect_indices_end\"].update(row[\"indexes\"][\"effect\"][\"end_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"drug\"].append(row[\"drug\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect\"].append(row[\"effect\"])\n",
    "        \n",
    "    else:\n",
    "        consolidated_dataset[row[\"text\"]] = {\n",
    "            \"text\": row[\"text\"],\n",
    "            \"drug\": [row[\"drug\"]],\n",
    "            \"effect\": [row[\"effect\"]],\n",
    "            # use sets because the indices can repeat for various reasons\n",
    "            \"drug_indices_start\": set(row[\"indexes\"][\"drug\"][\"start_char\"]),\n",
    "            \"drug_indices_end\": set(row[\"indexes\"][\"drug\"][\"end_char\"]),\n",
    "            \"effect_indices_start\": set(row[\"indexes\"][\"effect\"][\"start_char\"]),\n",
    "            \"effect_indices_end\": set(row[\"indexes\"][\"effect\"][\"end_char\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "With the dataset consolidated, we need to assign per-token labels to each sentence. First, we re-define our Python data structure as a Hugging Face Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(consolidated_dataset.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>effect</th>\n",
       "      <th>drug_indices_start</th>\n",
       "      <th>drug_indices_end</th>\n",
       "      <th>effect_indices_start</th>\n",
       "      <th>effect_indices_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intravenous azithromycin-induced ototoxicity.</td>\n",
       "      <td>[azithromycin]</td>\n",
       "      <td>[ototoxicity]</td>\n",
       "      <td>{12}</td>\n",
       "      <td>{24}</td>\n",
       "      <td>{33}</td>\n",
       "      <td>{44}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immobilization, while Paget's bone disease was...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[increased calcium-release]</td>\n",
       "      <td>{91}</td>\n",
       "      <td>{109}</td>\n",
       "      <td>{143}</td>\n",
       "      <td>{168}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unaccountable severe hypercalcemia in a patien...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[hypercalcemia]</td>\n",
       "      <td>{84}</td>\n",
       "      <td>{102}</td>\n",
       "      <td>{21}</td>\n",
       "      <td>{34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS: We report two cases of pseudoporphyri...</td>\n",
       "      <td>[naproxen, oxaprozin]</td>\n",
       "      <td>[pseudoporphyria, pseudoporphyria]</td>\n",
       "      <td>{58, 71}</td>\n",
       "      <td>{80, 66}</td>\n",
       "      <td>{32}</td>\n",
       "      <td>{47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naproxen, the most common offender, has been a...</td>\n",
       "      <td>[Naproxen]</td>\n",
       "      <td>[erythropoietic protoporphyria]</td>\n",
       "      <td>{0}</td>\n",
       "      <td>{8}</td>\n",
       "      <td>{134}</td>\n",
       "      <td>{163}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   drug  \\\n",
       "0      Intravenous azithromycin-induced ototoxicity.         [azithromycin]   \n",
       "1  Immobilization, while Paget's bone disease was...   [dihydrotachysterol]   \n",
       "2  Unaccountable severe hypercalcemia in a patien...   [dihydrotachysterol]   \n",
       "3  METHODS: We report two cases of pseudoporphyri...  [naproxen, oxaprozin]   \n",
       "4  Naproxen, the most common offender, has been a...             [Naproxen]   \n",
       "\n",
       "                               effect drug_indices_start drug_indices_end  \\\n",
       "0                       [ototoxicity]               {12}             {24}   \n",
       "1         [increased calcium-release]               {91}            {109}   \n",
       "2                     [hypercalcemia]               {84}            {102}   \n",
       "3  [pseudoporphyria, pseudoporphyria]           {58, 71}         {80, 66}   \n",
       "4     [erythropoietic protoporphyria]                {0}              {8}   \n",
       "\n",
       "  effect_indices_start effect_indices_end  \n",
       "0                 {33}               {44}  \n",
       "1                {143}              {168}  \n",
       "2                 {21}               {34}  \n",
       "3                 {32}               {47}  \n",
       "4                {134}              {163}  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since no spans overlap, we can sort to get 1:1 matched index spans\n",
    "# note that sets don't preserve insertion order\n",
    "\n",
    "df[\"drug_indices_start\"] = df[\"drug_indices_start\"].apply(list).apply(sorted)\n",
    "df[\"drug_indices_end\"] = df[\"drug_indices_end\"].apply(list).apply(sorted)\n",
    "df[\"effect_indices_start\"] = df[\"effect_indices_start\"].apply(list).apply(sorted)\n",
    "df[\"effect_indices_end\"] = df[\"effect_indices_end\"].apply(list).apply(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to JSON to then import into Dataset object\n",
    "df.to_json(\"dataset.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4d50f1e083f6f7fa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/ec2-user/.cache/huggingface/datasets/json/default-4d50f1e083f6f7fa/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077d7aef708145fcb1b25446f715d1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f4d5c5306b4409b6ea5b9dc1f0deb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/ec2-user/.cache/huggingface/datasets/json/default-4d50f1e083f6f7fa/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11431d5724924444ac3e118ba8024134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cons_dataset = load_dataset(\"json\", data_files=\"dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no train-test provided, so we create our own\n",
    "cons_dataset = cons_dataset[\"train\"].train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'drug', 'effect', 'drug_indices_start', 'drug_indices_end', 'effect_indices_start', 'effect_indices_end'],\n",
       "        num_rows: 3203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'drug', 'effect', 'drug_indices_start', 'drug_indices_end', 'effect_indices_start', 'effect_indices_end'],\n",
       "        num_rows: 1068\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Token Labeling\n",
    "\n",
    "Finally, we can label each token with its entity. We use BIO tagging on two entities, `DRUG` and `EFFECT`. This results in five possible classes for each token:\n",
    "\n",
    "* `O` - outside any entity we care about\n",
    "* `B-DRUG` - the beginning of a `DRUG` entity\n",
    "* `I-DRUG` - inside a `DRUG` entity\n",
    "* `B-EFFECT` - the beginning of an `EFFECT` entity\n",
    "* `I-EFFECT` - inside an `EFFECT` entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-DRUG', 'I-DRUG', 'B-EFFECT', 'I-EFFECT']\n",
    "\n",
    "custom_seq = Sequence(feature=ClassLabel(num_classes=5, \n",
    "                                         names=label_list,\n",
    "                                         names_file=None, id=None), length=-1, id=None)\n",
    "\n",
    "cons_dataset[\"train\"].features[\"ner_tags\"] = custom_seq\n",
    "cons_dataset[\"test\"].features[\"ner_tags\"] = custom_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_row_labels(row, verbose=False):\n",
    "    \"\"\" Given a row from the consolidated `Ade_corpus_v2_drug_ade_relation` dataset, \n",
    "    generates BIO tags for drug and effect entities. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    text = row[\"text\"]\n",
    "\n",
    "    labels = []\n",
    "    label = \"O\"\n",
    "    prefix = \"\"\n",
    "    \n",
    "    # while iterating through tokens, increment to traverse all drug and effect spans\n",
    "    drug_index = 0\n",
    "    effect_index = 0\n",
    "    \n",
    "    tokens = tokenizer(text, return_offsets_mapping=True)\n",
    "\n",
    "    for n in range(len(tokens[\"input_ids\"])):\n",
    "        offset_start, offset_end = tokens[\"offset_mapping\"][n]\n",
    "\n",
    "        # should only happen for [CLS] and [SEP]\n",
    "        if offset_end - offset_start == 0:\n",
    "            labels.append(-100)\n",
    "            continue\n",
    "        \n",
    "        if drug_index < len(row[\"drug_indices_start\"]) and offset_start == row[\"drug_indices_start\"][drug_index]:\n",
    "            label = \"DRUG\"\n",
    "            prefix = \"B-\"\n",
    "\n",
    "        elif effect_index < len(row[\"effect_indices_start\"]) and offset_start == row[\"effect_indices_start\"][effect_index]:\n",
    "            label = \"EFFECT\"\n",
    "            prefix = \"B-\"\n",
    "        \n",
    "        labels.append(label_list.index(f\"{prefix}{label}\"))\n",
    "            \n",
    "        if drug_index < len(row[\"drug_indices_end\"]) and offset_end == row[\"drug_indices_end\"][drug_index]:\n",
    "            label = \"O\"\n",
    "            prefix = \"\"\n",
    "            drug_index += 1\n",
    "            \n",
    "        elif effect_index < len(row[\"effect_indices_end\"]) and offset_end == row[\"effect_indices_end\"][effect_index]:\n",
    "            label = \"O\"\n",
    "            prefix = \"\"\n",
    "            effect_index += 1\n",
    "\n",
    "        # need to transition \"inside\" if we just entered an entity\n",
    "        if prefix == \"B-\":\n",
    "            prefix = \"I-\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{row}\\n\")\n",
    "        orig = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"])\n",
    "        for n in range(len(labels)):\n",
    "            print(orig[n], labels[n])\n",
    "    tokens[\"labels\"] = labels\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Ampicillin-associated seizures.', 'drug': ['Ampicillin'], 'effect': ['seizures'], 'drug_indices_start': [0], 'drug_indices_end': [10], 'effect_indices_start': [22], 'effect_indices_end': [30]}\n",
      "\n",
      "[CLS] -100\n",
      "ampicillin 1\n",
      "- 0\n",
      "associated 0\n",
      "seizures 3\n",
      ". 0\n",
      "[SEP] -100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [102, 26728, 579, 1111, 12787, 205, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 10), (10, 11), (11, 21), (22, 30), (30, 31), (0, 0)], 'labels': [-100, 1, 0, 0, 3, 0, -100]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing out...\n",
    "\n",
    "generate_row_labels(cons_dataset[\"train\"][2], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441f07a2efa34f8fa561fc16ca7ec257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3203 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c895eb15403b400282b4857f91d093fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1068 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeled_dataset = cons_dataset.map(generate_row_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SciBERT Model Fine-Tuning\n",
    "\n",
    "We are now ready to fine-tune the SciBERT model on our dataset. This section is modified from the following ðŸ¤— notebook provided here: https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"allenai/scibert_scivocab_uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.05,\n",
    "    logging_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=labeled_dataset[\"train\"],\n",
    "    eval_dataset=labeled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: drug, effect_indices_end, offset_mapping, drug_indices_start, text, effect, drug_indices_end, effect_indices_start.\n",
      "***** Running training *****\n",
      "  Num examples = 3203\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1005' max='1005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1005/1005 02:08, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.147024</td>\n",
       "      <td>0.810579</td>\n",
       "      <td>0.904463</td>\n",
       "      <td>0.854951</td>\n",
       "      <td>0.952808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.132503</td>\n",
       "      <td>0.838336</td>\n",
       "      <td>0.906677</td>\n",
       "      <td>0.871168</td>\n",
       "      <td>0.958644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.132246</td>\n",
       "      <td>0.854145</td>\n",
       "      <td>0.915898</td>\n",
       "      <td>0.883944</td>\n",
       "      <td>0.960842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.133181</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.909627</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.962030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.136563</td>\n",
       "      <td>0.860602</td>\n",
       "      <td>0.917743</td>\n",
       "      <td>0.888254</td>\n",
       "      <td>0.962823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: drug, effect_indices_end, offset_mapping, drug_indices_start, text, effect, drug_indices_end, effect_indices_start.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: drug, effect_indices_end, offset_mapping, drug_indices_start, text, effect, drug_indices_end, effect_indices_start.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to scibert_scivocab_uncased-finetuned-ner/checkpoint-500\n",
      "Configuration saved in scibert_scivocab_uncased-finetuned-ner/checkpoint-500/config.json\n",
      "Model weights saved in scibert_scivocab_uncased-finetuned-ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in scibert_scivocab_uncased-finetuned-ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in scibert_scivocab_uncased-finetuned-ner/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: drug, effect_indices_end, offset_mapping, drug_indices_start, text, effect, drug_indices_end, effect_indices_start.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: drug, effect_indices_end, offset_mapping, drug_indices_start, text, effect, drug_indices_end, effect_indices_start.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to scibert_scivocab_uncased-finetuned-ner/checkpoint-1000\n",
      "Configuration saved in scibert_scivocab_uncased-finetuned-ner/checkpoint-1000/config.json\n",
      "Model weights saved in scibert_scivocab_uncased-finetuned-ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in scibert_scivocab_uncased-finetuned-ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in scibert_scivocab_uncased-finetuned-ner/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: drug, effect_indices_end, offset_mapping, drug_indices_start, text, effect, drug_indices_end, effect_indices_start.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1005, training_loss=0.12553799401699978, metrics={'train_runtime': 128.9417, 'train_samples_per_second': 124.203, 'train_steps_per_second': 7.794, 'total_flos': 438556142082630.0, 'train_loss': 0.12553799401699978, 'epoch': 5.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: drug, effect_indices_end, offset_mapping, drug_indices_start, text, effect, drug_indices_end, effect_indices_start.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'DRUG': {'precision': 0.9234731420161884,\n",
       "  'recall': 0.9661277906081601,\n",
       "  'f1': 0.9443190368698269,\n",
       "  'number': 1299},\n",
       " 'EFFECT': {'precision': 0.8048302872062664,\n",
       "  'recall': 0.873229461756374,\n",
       "  'f1': 0.8376358695652174,\n",
       "  'number': 1412},\n",
       " 'overall_precision': 0.8606018678657904,\n",
       " 'overall_recall': 0.917742530431575,\n",
       " 'overall_f1': 0.888254194930382,\n",
       " 'overall_accuracy': 0.962822868258943}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(labeled_dataset[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## See Model Outputs\n",
    "\n",
    "We load our fine-tuned model into a `pipeline` object to run arbitrary input against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_ner_model = pipeline(task=\"ner\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_0',\n",
       "  'score': 0.99228,\n",
       "  'index': 1,\n",
       "  'word': 'possible',\n",
       "  'start': 0,\n",
       "  'end': 8},\n",
       " {'entity': 'LABEL_3',\n",
       "  'score': 0.9958305,\n",
       "  'index': 2,\n",
       "  'word': 'serotonin',\n",
       "  'start': 9,\n",
       "  'end': 18},\n",
       " {'entity': 'LABEL_4',\n",
       "  'score': 0.99691534,\n",
       "  'index': 3,\n",
       "  'word': 'syndrome',\n",
       "  'start': 19,\n",
       "  'end': 27},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9987228,\n",
       "  'index': 4,\n",
       "  'word': 'associated',\n",
       "  'start': 28,\n",
       "  'end': 38},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9990265,\n",
       "  'index': 5,\n",
       "  'word': 'with',\n",
       "  'start': 39,\n",
       "  'end': 43},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.99770975,\n",
       "  'index': 6,\n",
       "  'word': 'clo',\n",
       "  'start': 44,\n",
       "  'end': 47},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.9988942,\n",
       "  'index': 7,\n",
       "  'word': '##mi',\n",
       "  'start': 47,\n",
       "  'end': 49},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.99920785,\n",
       "  'index': 8,\n",
       "  'word': '##pr',\n",
       "  'start': 49,\n",
       "  'end': 51},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.9991023,\n",
       "  'index': 9,\n",
       "  'word': '##amine',\n",
       "  'start': 51,\n",
       "  'end': 56},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9997228,\n",
       "  'index': 10,\n",
       "  'word': 'after',\n",
       "  'start': 57,\n",
       "  'end': 62},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9997378,\n",
       "  'index': 11,\n",
       "  'word': 'withdrawal',\n",
       "  'start': 63,\n",
       "  'end': 73},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9996466,\n",
       "  'index': 12,\n",
       "  'word': 'of',\n",
       "  'start': 74,\n",
       "  'end': 76},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.8636527,\n",
       "  'index': 13,\n",
       "  'word': 'clo',\n",
       "  'start': 77,\n",
       "  'end': 80},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.8610073,\n",
       "  'index': 14,\n",
       "  'word': '##za',\n",
       "  'start': 80,\n",
       "  'end': 82},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.9185396,\n",
       "  'index': 15,\n",
       "  'word': '##pine',\n",
       "  'start': 82,\n",
       "  'end': 86},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9995602,\n",
       "  'index': 16,\n",
       "  'word': '.',\n",
       "  'start': 86,\n",
       "  'end': 87}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# something from our validation set\n",
    "effect_ner_model(labeled_dataset[\"test\"][4][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We try out the first few examples of adverse effects from the Wikipedia page on adverse effects and visualize with the displaCy library:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Adverse_effect#Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_entities(sentence):\n",
    "    tokens = effect_ner_model(sentence)\n",
    "    entities = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        label = int(token[\"entity\"][-1])\n",
    "        if label != 0:\n",
    "            token[\"label\"] = label_list[label]\n",
    "            entities.append(token)\n",
    "    \n",
    "    params = [{\"text\": sentence,\n",
    "               \"ents\": entities,\n",
    "               \"title\": None}]\n",
    "    \n",
    "    html = displacy.render(params, style=\"ent\", manual=True, options={\n",
    "        \"colors\": {\n",
    "                   \"B-DRUG\": \"#f08080\",\n",
    "                   \"I-DRUG\": \"#f08080\",\n",
    "                   \"B-EFFECT\": \"#9bddff\",\n",
    "                   \"I-EFFECT\": \"#9bddff\",\n",
    "               },\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Abortion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-EFFECT</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    misc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-EFFECT</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    arri\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    uterine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-EFFECT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hemorrhage\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " associated with \n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    oprost\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ol\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cyto\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tec\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       "), a labor-inducing drug.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Addiction to many sedatives and analgesics, such as \n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diaz\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    epa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    m\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    morphine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-DRUG</span>\n",
       "</mark>\n",
       ", etc.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Birth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-EFFECT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    defects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " associated with \n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ido\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    e\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bleeding\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-EFFECT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    of\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    intestine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " associated with \n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    aspirin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-DRUG</span>\n",
       "</mark>\n",
       " therapy</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cardiovascular\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-EFFECT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    disease\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " associated with COX-2 inhibitors (i.e. \n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Vio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-DRUG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    xx\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-DRUG</span>\n",
       "</mark>\n",
       ")</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Deaf\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-EFFECT</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ness\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    kidney\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-EFFECT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #9bddff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    failure\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-EFFECT</span>\n",
       "</mark>\n",
       " associated with \n",
       "<mark class=\"entity\" style=\"background: #f08080; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    gentamicin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-DRUG</span>\n",
       "</mark>\n",
       " (an antibiotic)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"Abortion, miscarriage or uterine hemorrhage associated with misoprostol (Cytotec), a labor-inducing drug.\",\n",
    "    \"Addiction to many sedatives and analgesics, such as diazepam, morphine, etc.\",\n",
    "    \"Birth defects associated with thalidomide\",\n",
    "    \"Bleeding of the intestine associated with aspirin therapy\",\n",
    "    \"Cardiovascular disease associated with COX-2 inhibitors (i.e. Vioxx)\",\n",
    "    \"Deafness and kidney failure associated with gentamicin (an antibiotic)\"\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    visualize_entities(example)\n",
    "    print(f\"{'*' * 50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
